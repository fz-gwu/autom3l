['model.base_models.hf_text-electra.model.embeddings.position_ids', 'model.base_models.hf_text-electra.model.embeddings.word_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.position_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.token_type_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.LayerNorm.weight', 'model.base_models.hf_text-electra.model.embeddings.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.bias', 'model.base_models.hf_text-electra.head.weight', 'model.base_models.hf_text-electra.head.bias', 'model.base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.weight', 'model.base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.bias', 'model.base_models.numerical_transformer.head.normalization.weight', 'model.base_models.numerical_transformer.head.normalization.bias', 'model.base_models.numerical_transformer.head.linear.weight', 'model.base_models.numerical_transformer.head.linear.bias', 'model.base_models.categorical_transformer.categorical_feature_tokenizer.bias', 'model.base_models.categorical_transformer.categorical_feature_tokenizer.embeddings.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.bias', 'model.base_models.categorical_transformer.head.normalization.weight', 'model.base_models.categorical_transformer.head.normalization.bias', 'model.base_models.categorical_transformer.head.linear.weight', 'model.base_models.categorical_transformer.head.linear.bias', 'model.base_models.timm_image-swin_transformer.model.patch_embed.proj.weight', 'model.base_models.timm_image-swin_transformer.model.patch_embed.proj.bias', 'model.base_models.timm_image-swin_transformer.model.patch_embed.norm.weight', 'model.base_models.timm_image-swin_transformer.model.patch_embed.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.norm.weight', 'model.base_models.timm_image-swin_transformer.model.norm.bias', 'model.base_models.timm_image-swin_transformer.head.weight', 'model.base_models.timm_image-swin_transformer.head.bias', 'model.linear_layers.hf_text-electra.weight', 'model.linear_layers.hf_text-electra.bias', 'model.linear_layers.numerical_transformer.weight', 'model.linear_layers.numerical_transformer.bias', 'model.linear_layers.categorical_transformer.weight', 'model.linear_layers.categorical_transformer.bias', 'model.linear_layers.timm_image-swin_transformer.weight', 'model.linear_layers.timm_image-swin_transformer.bias', 'model.fusion_model.0.weight', 'model.fusion_model.0.bias', 'model.fusion_model.2.weight', 'model.fusion_model.2.bias', 'model.fusion_head.weight', 'model.fusion_head.bias']
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ in <module>:8                                                                                    │
│                                                                                                  │
│   5 os.environ["OPENAI_API_KEY"] = "sk-proj-a4DBFe76t6yhAmA6LzinROBjp5xTlYPChJo6uEYgfw5MHHHi     │
│   6 os.environ["OPENAI_API_BASE"] = "http://172.16.23.85:30592/chatgpt/api/ask"                  │
│   7                                                                                              │
│ ❱ 8 predictor = AutoM3LPredictor.load("/home/ubuntu/autom3l/autom3l_code/output/petfinder_k1     │
│   9                                                                                              │
│                                                                                                  │
│ /home/ubuntu/autom3l/autom3l_code/multimodal/src/autom3l/multimodal/predictor_llm.py:3621 in     │
│ load                                                                                             │
│                                                                                                  │
│   3618 │   │   │   resume=resume,                                                                │
│   3619 │   │   )                                                                                 │
│   3620 │   │                                                                                     │
│ ❱ 3621 │   │   model = cls._load_state_dict(                                                     │
│   3622 │   │   │   model=model,                                                                  │
│   3623 │   │   │   path=load_path,                                                               │
│   3624 │   │   │   strict=not efficient_finetune or efficient_finetune == "None",                │
│                                                                                                  │
│ /home/ubuntu/autom3l/autom3l_code/multimodal/src/autom3l/multimodal/predictor_llm.py:3341 in     │
│ _load_state_dict                                                                                 │
│                                                                                                  │
│   3338 │   │   state_dict = {k.partition(prefix)[2]: v for k, v in state_dict.items() if k.star  │
│   3339 │   │   #print("new_state_dict", state_dict)                                              │
│   3340 │   │   strict = True                                                                     │
│ ❱ 3341 │   │   load_result = model.load_state_dict(state_dict, strict=strict)                    │
│   3342 │   │   '''                                                                               │
│   3343 │   │   assert (                                                                          │
│   3344 │   │   │   len(load_result.unexpected_keys) == 0                                         │
│                                                                                                  │
│ /home/ubuntu/.conda/envs/autom3l/lib/python3.9/site-packages/torch/nn/modules/module.py:1497 in  │
│ load_state_dict                                                                                  │
│                                                                                                  │
│   1494 │   │   │   │   │   │   ', '.join('"{}"'.format(k) for k in missing_keys)))               │
│   1495 │   │                                                                                     │
│   1496 │   │   if len(error_msgs) > 0:                                                           │
│ ❱ 1497 │   │   │   raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(     │
│   1498 │   │   │   │   │   │   │      self.__class__.__name__, "\n\t".join(error_msgs)))         │
│   1499 │   │   return _IncompatibleKeys(missing_keys, unexpected_keys)                           │
│   1500                                                                                           │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
RuntimeError: Error(s) in loading state_dict for MultimodalFusionMLP:
        Missing key(s) in state_dict: "model.0.categorical_feature_tokenizer.bias", 
"model.0.categorical_feature_tokenizer.embeddings.weight", "model.0.transformer.blocks.0.attention.W_q.weight", 
"model.0.transformer.blocks.0.attention.W_q.bias", "model.0.transformer.blocks.0.attention.W_k.weight", 
"model.0.transformer.blocks.0.attention.W_k.bias", "model.0.transformer.blocks.0.attention.W_v.weight", 
"model.0.transformer.blocks.0.attention.W_v.bias", "model.0.transformer.blocks.0.attention.W_out.weight", 
"model.0.transformer.blocks.0.attention.W_out.bias", "model.0.transformer.blocks.0.ffn.linear_first.weight", 
"model.0.transformer.blocks.0.ffn.linear_first.bias", "model.0.transformer.blocks.0.ffn.linear_second.weight", 
"model.0.transformer.blocks.0.ffn.linear_second.bias", "model.0.transformer.blocks.0.ffn_normalization.weight", 
"model.0.transformer.blocks.0.ffn_normalization.bias", "model.0.transformer.blocks.1.attention.W_q.weight", 
"model.0.transformer.blocks.1.attention.W_q.bias", "model.0.transformer.blocks.1.attention.W_k.weight", 
"model.0.transformer.blocks.1.attention.W_k.bias", "model.0.transformer.blocks.1.attention.W_v.weight", 
"model.0.transformer.blocks.1.attention.W_v.bias", "model.0.transformer.blocks.1.attention.W_out.weight", 
"model.0.transformer.blocks.1.attention.W_out.bias", "model.0.transformer.blocks.1.ffn.linear_first.weight", 
"model.0.transformer.blocks.1.ffn.linear_first.bias", "model.0.transformer.blocks.1.ffn.linear_second.weight", 
"model.0.transformer.blocks.1.ffn.linear_second.bias", 
"model.0.transformer.blocks.1.attention_normalization.weight", 
"model.0.transformer.blocks.1.attention_normalization.bias", 
"model.0.transformer.blocks.1.ffn_normalization.weight", "model.0.transformer.blocks.1.ffn_normalization.bias", 
"model.0.transformer.blocks.2.attention.W_q.weight", "model.0.transformer.blocks.2.attention.W_q.bias", 
"model.0.transformer.blocks.2.attention.W_k.weight", "model.0.transformer.blocks.2.attention.W_k.bias", 
"model.0.transformer.blocks.2.attention.W_v.weight", "model.0.transformer.blocks.2.attention.W_v.bias", 
"model.0.transformer.blocks.2.attention.W_out.weight", "model.0.transformer.blocks.2.attention.W_out.bias", 
"model.0.transformer.blocks.2.ffn.linear_first.weight", "model.0.transformer.blocks.2.ffn.linear_first.bias", 
"model.0.transformer.blocks.2.ffn.linear_second.weight", "model.0.transformer.blocks.2.ffn.linear_second.bias", 
"model.0.transformer.blocks.2.attention_normalization.weight", 
"model.0.transformer.blocks.2.attention_normalization.bias", 
"model.0.transformer.blocks.2.ffn_normalization.weight", "model.0.transformer.blocks.2.ffn_normalization.bias", 
"model.0.head.normalization.weight", "model.0.head.normalization.bias", "model.0.head.linear.weight", 
"model.0.head.linear.bias", "model.1.model.embeddings.position_ids", 
"model.1.model.embeddings.word_embeddings.weight", "model.1.model.embeddings.position_embeddings.weight", 
"model.1.model.embeddings.token_type_embeddings.weight", "model.1.model.embeddings.LayerNorm.weight", 
"model.1.model.embeddings.LayerNorm.bias", "model.1.model.encoder.layer.0.attention.self.query.weight", 
"model.1.model.encoder.layer.0.attention.self.query.bias", 
"model.1.model.encoder.layer.0.attention.self.key.weight", "model.1.model.encoder.layer.0.attention.self.key.bias",
"model.1.model.encoder.layer.0.attention.self.value.weight", 
"model.1.model.encoder.layer.0.attention.self.value.bias", 
"model.1.model.encoder.layer.0.attention.output.dense.weight", 
"model.1.model.encoder.layer.0.attention.output.dense.bias", 
"model.1.model.encoder.layer.0.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.0.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.0.intermediate.dense.weight", "model.1.model.encoder.layer.0.intermediate.dense.bias",
"model.1.model.encoder.layer.0.output.dense.weight", "model.1.model.encoder.layer.0.output.dense.bias", 
"model.1.model.encoder.layer.0.output.LayerNorm.weight", "model.1.model.encoder.layer.0.output.LayerNorm.bias", 
"model.1.model.encoder.layer.1.attention.self.query.weight", 
"model.1.model.encoder.layer.1.attention.self.query.bias", 
"model.1.model.encoder.layer.1.attention.self.key.weight", "model.1.model.encoder.layer.1.attention.self.key.bias",
"model.1.model.encoder.layer.1.attention.self.value.weight", 
"model.1.model.encoder.layer.1.attention.self.value.bias", 
"model.1.model.encoder.layer.1.attention.output.dense.weight", 
"model.1.model.encoder.layer.1.attention.output.dense.bias", 
"model.1.model.encoder.layer.1.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.1.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.1.intermediate.dense.weight", "model.1.model.encoder.layer.1.intermediate.dense.bias",
"model.1.model.encoder.layer.1.output.dense.weight", "model.1.model.encoder.layer.1.output.dense.bias", 
"model.1.model.encoder.layer.1.output.LayerNorm.weight", "model.1.model.encoder.layer.1.output.LayerNorm.bias", 
"model.1.model.encoder.layer.2.attention.self.query.weight", 
"model.1.model.encoder.layer.2.attention.self.query.bias", 
"model.1.model.encoder.layer.2.attention.self.key.weight", "model.1.model.encoder.layer.2.attention.self.key.bias",
"model.1.model.encoder.layer.2.attention.self.value.weight", 
"model.1.model.encoder.layer.2.attention.self.value.bias", 
"model.1.model.encoder.layer.2.attention.output.dense.weight", 
"model.1.model.encoder.layer.2.attention.output.dense.bias", 
"model.1.model.encoder.layer.2.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.2.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.2.intermediate.dense.weight", "model.1.model.encoder.layer.2.intermediate.dense.bias",
"model.1.model.encoder.layer.2.output.dense.weight", "model.1.model.encoder.layer.2.output.dense.bias", 
"model.1.model.encoder.layer.2.output.LayerNorm.weight", "model.1.model.encoder.layer.2.output.LayerNorm.bias", 
"model.1.model.encoder.layer.3.attention.self.query.weight", 
"model.1.model.encoder.layer.3.attention.self.query.bias", 
"model.1.model.encoder.layer.3.attention.self.key.weight", "model.1.model.encoder.layer.3.attention.self.key.bias",
"model.1.model.encoder.layer.3.attention.self.value.weight", 
"model.1.model.encoder.layer.3.attention.self.value.bias", 
"model.1.model.encoder.layer.3.attention.output.dense.weight", 
"model.1.model.encoder.layer.3.attention.output.dense.bias", 
"model.1.model.encoder.layer.3.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.3.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.3.intermediate.dense.weight", "model.1.model.encoder.layer.3.intermediate.dense.bias",
"model.1.model.encoder.layer.3.output.dense.weight", "model.1.model.encoder.layer.3.output.dense.bias", 
"model.1.model.encoder.layer.3.output.LayerNorm.weight", "model.1.model.encoder.layer.3.output.LayerNorm.bias", 
"model.1.model.encoder.layer.4.attention.self.query.weight", 
"model.1.model.encoder.layer.4.attention.self.query.bias", 
"model.1.model.encoder.layer.4.attention.self.key.weight", "model.1.model.encoder.layer.4.attention.self.key.bias",
"model.1.model.encoder.layer.4.attention.self.value.weight", 
"model.1.model.encoder.layer.4.attention.self.value.bias", 
"model.1.model.encoder.layer.4.attention.output.dense.weight", 
"model.1.model.encoder.layer.4.attention.output.dense.bias", 
"model.1.model.encoder.layer.4.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.4.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.4.intermediate.dense.weight", "model.1.model.encoder.layer.4.intermediate.dense.bias",
"model.1.model.encoder.layer.4.output.dense.weight", "model.1.model.encoder.layer.4.output.dense.bias", 
"model.1.model.encoder.layer.4.output.LayerNorm.weight", "model.1.model.encoder.layer.4.output.LayerNorm.bias", 
"model.1.model.encoder.layer.5.attention.self.query.weight", 
"model.1.model.encoder.layer.5.attention.self.query.bias", 
"model.1.model.encoder.layer.5.attention.self.key.weight", "model.1.model.encoder.layer.5.attention.self.key.bias",
"model.1.model.encoder.layer.5.attention.self.value.weight", 
"model.1.model.encoder.layer.5.attention.self.value.bias", 
"model.1.model.encoder.layer.5.attention.output.dense.weight", 
"model.1.model.encoder.layer.5.attention.output.dense.bias", 
"model.1.model.encoder.layer.5.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.5.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.5.intermediate.dense.weight", "model.1.model.encoder.layer.5.intermediate.dense.bias",
"model.1.model.encoder.layer.5.output.dense.weight", "model.1.model.encoder.layer.5.output.dense.bias", 
"model.1.model.encoder.layer.5.output.LayerNorm.weight", "model.1.model.encoder.layer.5.output.LayerNorm.bias", 
"model.1.model.encoder.layer.6.attention.self.query.weight", 
"model.1.model.encoder.layer.6.attention.self.query.bias", 
"model.1.model.encoder.layer.6.attention.self.key.weight", "model.1.model.encoder.layer.6.attention.self.key.bias",
"model.1.model.encoder.layer.6.attention.self.value.weight", 
"model.1.model.encoder.layer.6.attention.self.value.bias", 
"model.1.model.encoder.layer.6.attention.output.dense.weight", 
"model.1.model.encoder.layer.6.attention.output.dense.bias", 
"model.1.model.encoder.layer.6.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.6.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.6.intermediate.dense.weight", "model.1.model.encoder.layer.6.intermediate.dense.bias",
"model.1.model.encoder.layer.6.output.dense.weight", "model.1.model.encoder.layer.6.output.dense.bias", 
"model.1.model.encoder.layer.6.output.LayerNorm.weight", "model.1.model.encoder.layer.6.output.LayerNorm.bias", 
"model.1.model.encoder.layer.7.attention.self.query.weight", 
"model.1.model.encoder.layer.7.attention.self.query.bias", 
"model.1.model.encoder.layer.7.attention.self.key.weight", "model.1.model.encoder.layer.7.attention.self.key.bias",
"model.1.model.encoder.layer.7.attention.self.value.weight", 
"model.1.model.encoder.layer.7.attention.self.value.bias", 
"model.1.model.encoder.layer.7.attention.output.dense.weight", 
"model.1.model.encoder.layer.7.attention.output.dense.bias", 
"model.1.model.encoder.layer.7.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.7.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.7.intermediate.dense.weight", "model.1.model.encoder.layer.7.intermediate.dense.bias",
"model.1.model.encoder.layer.7.output.dense.weight", "model.1.model.encoder.layer.7.output.dense.bias", 
"model.1.model.encoder.layer.7.output.LayerNorm.weight", "model.1.model.encoder.layer.7.output.LayerNorm.bias", 
"model.1.model.encoder.layer.8.attention.self.query.weight", 
"model.1.model.encoder.layer.8.attention.self.query.bias", 
"model.1.model.encoder.layer.8.attention.self.key.weight", "model.1.model.encoder.layer.8.attention.self.key.bias",
"model.1.model.encoder.layer.8.attention.self.value.weight", 
"model.1.model.encoder.layer.8.attention.self.value.bias", 
"model.1.model.encoder.layer.8.attention.output.dense.weight", 
"model.1.model.encoder.layer.8.attention.output.dense.bias", 
"model.1.model.encoder.layer.8.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.8.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.8.intermediate.dense.weight", "model.1.model.encoder.layer.8.intermediate.dense.bias",
"model.1.model.encoder.layer.8.output.dense.weight", "model.1.model.encoder.layer.8.output.dense.bias", 
"model.1.model.encoder.layer.8.output.LayerNorm.weight", "model.1.model.encoder.layer.8.output.LayerNorm.bias", 
"model.1.model.encoder.layer.9.attention.self.query.weight", 
"model.1.model.encoder.layer.9.attention.self.query.bias", 
"model.1.model.encoder.layer.9.attention.self.key.weight", "model.1.model.encoder.layer.9.attention.self.key.bias",
"model.1.model.encoder.layer.9.attention.self.value.weight", 
"model.1.model.encoder.layer.9.attention.self.value.bias", 
"model.1.model.encoder.layer.9.attention.output.dense.weight", 
"model.1.model.encoder.layer.9.attention.output.dense.bias", 
"model.1.model.encoder.layer.9.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.9.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.9.intermediate.dense.weight", "model.1.model.encoder.layer.9.intermediate.dense.bias",
"model.1.model.encoder.layer.9.output.dense.weight", "model.1.model.encoder.layer.9.output.dense.bias", 
"model.1.model.encoder.layer.9.output.LayerNorm.weight", "model.1.model.encoder.layer.9.output.LayerNorm.bias", 
"model.1.model.encoder.layer.10.attention.self.query.weight", 
"model.1.model.encoder.layer.10.attention.self.query.bias", 
"model.1.model.encoder.layer.10.attention.self.key.weight", 
"model.1.model.encoder.layer.10.attention.self.key.bias", 
"model.1.model.encoder.layer.10.attention.self.value.weight", 
"model.1.model.encoder.layer.10.attention.self.value.bias", 
"model.1.model.encoder.layer.10.attention.output.dense.weight", 
"model.1.model.encoder.layer.10.attention.output.dense.bias", 
"model.1.model.encoder.layer.10.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.10.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.10.intermediate.dense.weight", 
"model.1.model.encoder.layer.10.intermediate.dense.bias", "model.1.model.encoder.layer.10.output.dense.weight", 
"model.1.model.encoder.layer.10.output.dense.bias", "model.1.model.encoder.layer.10.output.LayerNorm.weight", 
"model.1.model.encoder.layer.10.output.LayerNorm.bias", 
"model.1.model.encoder.layer.11.attention.self.query.weight", 
"model.1.model.encoder.layer.11.attention.self.query.bias", 
"model.1.model.encoder.layer.11.attention.self.key.weight", 
"model.1.model.encoder.layer.11.attention.self.key.bias", 
"model.1.model.encoder.layer.11.attention.self.value.weight", 
"model.1.model.encoder.layer.11.attention.self.value.bias", 
"model.1.model.encoder.layer.11.attention.output.dense.weight", 
"model.1.model.encoder.layer.11.attention.output.dense.bias", 
"model.1.model.encoder.layer.11.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.11.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.11.intermediate.dense.weight", 
"model.1.model.encoder.layer.11.intermediate.dense.bias", "model.1.model.encoder.layer.11.output.dense.weight", 
"model.1.model.encoder.layer.11.output.dense.bias", "model.1.model.encoder.layer.11.output.LayerNorm.weight", 
"model.1.model.encoder.layer.11.output.LayerNorm.bias", "model.1.head.weight", "model.1.head.bias", 
"model.2.numerical_feature_tokenizer.layers.0.weight", "model.2.numerical_feature_tokenizer.layers.0.bias", 
"model.2.transformer.blocks.0.attention.W_q.weight", "model.2.transformer.blocks.0.attention.W_q.bias", 
"model.2.transformer.blocks.0.attention.W_k.weight", "model.2.transformer.blocks.0.attention.W_k.bias", 
"model.2.transformer.blocks.0.attention.W_v.weight", "model.2.transformer.blocks.0.attention.W_v.bias", 
"model.2.transformer.blocks.0.attention.W_out.weight", "model.2.transformer.blocks.0.attention.W_out.bias", 
"model.2.transformer.blocks.0.ffn.linear_first.weight", "model.2.transformer.blocks.0.ffn.linear_first.bias", 
"model.2.transformer.blocks.0.ffn.linear_second.weight", "model.2.transformer.blocks.0.ffn.linear_second.bias", 
"model.2.transformer.blocks.0.ffn_normalization.weight", "model.2.transformer.blocks.0.ffn_normalization.bias", 
"model.2.transformer.blocks.1.attention.W_q.weight", "model.2.transformer.blocks.1.attention.W_q.bias", 
"model.2.transformer.blocks.1.attention.W_k.weight", "model.2.transformer.blocks.1.attention.W_k.bias", 
"model.2.transformer.blocks.1.attention.W_v.weight", "model.2.transformer.blocks.1.attention.W_v.bias", 
"model.2.transformer.blocks.1.attention.W_out.weight", "model.2.transformer.blocks.1.attention.W_out.bias", 
"model.2.transformer.blocks.1.ffn.linear_first.weight", "model.2.transformer.blocks.1.ffn.linear_first.bias", 
"model.2.transformer.blocks.1.ffn.linear_second.weight", "model.2.transformer.blocks.1.ffn.linear_second.bias", 
"model.2.transformer.blocks.1.attention_normalization.weight", 
"model.2.transformer.blocks.1.attention_normalization.bias", 
"model.2.transformer.blocks.1.ffn_normalization.weight", "model.2.transformer.blocks.1.ffn_normalization.bias", 
"model.2.transformer.blocks.2.attention.W_q.weight", "model.2.transformer.blocks.2.attention.W_q.bias", 
"model.2.transformer.blocks.2.attention.W_k.weight", "model.2.transformer.blocks.2.attention.W_k.bias", 
"model.2.transformer.blocks.2.attention.W_v.weight", "model.2.transformer.blocks.2.attention.W_v.bias", 
"model.2.transformer.blocks.2.attention.W_out.weight", "model.2.transformer.blocks.2.attention.W_out.bias", 
"model.2.transformer.blocks.2.ffn.linear_first.weight", "model.2.transformer.blocks.2.ffn.linear_first.bias", 
"model.2.transformer.blocks.2.ffn.linear_second.weight", "model.2.transformer.blocks.2.ffn.linear_second.bias", 
"model.2.transformer.blocks.2.attention_normalization.weight", 
"model.2.transformer.blocks.2.attention_normalization.bias", 
"model.2.transformer.blocks.2.ffn_normalization.weight", "model.2.transformer.blocks.2.ffn_normalization.bias", 
"model.2.head.normalization.weight", "model.2.head.normalization.bias", "model.2.head.linear.weight", 
"model.2.head.linear.bias", "model.3.model.patch_embed.proj.weight", "model.3.model.patch_embed.proj.bias", 
"model.3.model.patch_embed.norm.weight", "model.3.model.patch_embed.norm.bias", 
"model.3.model.layers.0.blocks.0.norm1.weight", "model.3.model.layers.0.blocks.0.norm1.bias", 
"model.3.model.layers.0.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.0.blocks.0.attn.qkv.weight", "model.3.model.layers.0.blocks.0.attn.qkv.bias", 
"model.3.model.layers.0.blocks.0.attn.proj.weight", "model.3.model.layers.0.blocks.0.attn.proj.bias", 
"model.3.model.layers.0.blocks.0.norm2.weight", "model.3.model.layers.0.blocks.0.norm2.bias", 
"model.3.model.layers.0.blocks.0.mlp.fc1.weight", "model.3.model.layers.0.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.0.blocks.0.mlp.fc2.weight", "model.3.model.layers.0.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.0.blocks.1.norm1.weight", "model.3.model.layers.0.blocks.1.norm1.bias", 
"model.3.model.layers.0.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.0.blocks.1.attn.qkv.weight", "model.3.model.layers.0.blocks.1.attn.qkv.bias", 
"model.3.model.layers.0.blocks.1.attn.proj.weight", "model.3.model.layers.0.blocks.1.attn.proj.bias", 
"model.3.model.layers.0.blocks.1.norm2.weight", "model.3.model.layers.0.blocks.1.norm2.bias", 
"model.3.model.layers.0.blocks.1.mlp.fc1.weight", "model.3.model.layers.0.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.0.blocks.1.mlp.fc2.weight", "model.3.model.layers.0.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.1.downsample.norm.weight", "model.3.model.layers.1.downsample.norm.bias", 
"model.3.model.layers.1.downsample.reduction.weight", "model.3.model.layers.1.blocks.0.norm1.weight", 
"model.3.model.layers.1.blocks.0.norm1.bias", "model.3.model.layers.1.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.1.blocks.0.attn.qkv.weight", "model.3.model.layers.1.blocks.0.attn.qkv.bias", 
"model.3.model.layers.1.blocks.0.attn.proj.weight", "model.3.model.layers.1.blocks.0.attn.proj.bias", 
"model.3.model.layers.1.blocks.0.norm2.weight", "model.3.model.layers.1.blocks.0.norm2.bias", 
"model.3.model.layers.1.blocks.0.mlp.fc1.weight", "model.3.model.layers.1.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.1.blocks.0.mlp.fc2.weight", "model.3.model.layers.1.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.1.blocks.1.norm1.weight", "model.3.model.layers.1.blocks.1.norm1.bias", 
"model.3.model.layers.1.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.1.blocks.1.attn.qkv.weight", "model.3.model.layers.1.blocks.1.attn.qkv.bias", 
"model.3.model.layers.1.blocks.1.attn.proj.weight", "model.3.model.layers.1.blocks.1.attn.proj.bias", 
"model.3.model.layers.1.blocks.1.norm2.weight", "model.3.model.layers.1.blocks.1.norm2.bias", 
"model.3.model.layers.1.blocks.1.mlp.fc1.weight", "model.3.model.layers.1.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.1.blocks.1.mlp.fc2.weight", "model.3.model.layers.1.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.2.downsample.norm.weight", "model.3.model.layers.2.downsample.norm.bias", 
"model.3.model.layers.2.downsample.reduction.weight", "model.3.model.layers.2.blocks.0.norm1.weight", 
"model.3.model.layers.2.blocks.0.norm1.bias", "model.3.model.layers.2.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.0.attn.qkv.weight", "model.3.model.layers.2.blocks.0.attn.qkv.bias", 
"model.3.model.layers.2.blocks.0.attn.proj.weight", "model.3.model.layers.2.blocks.0.attn.proj.bias", 
"model.3.model.layers.2.blocks.0.norm2.weight", "model.3.model.layers.2.blocks.0.norm2.bias", 
"model.3.model.layers.2.blocks.0.mlp.fc1.weight", "model.3.model.layers.2.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.0.mlp.fc2.weight", "model.3.model.layers.2.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.1.norm1.weight", "model.3.model.layers.2.blocks.1.norm1.bias", 
"model.3.model.layers.2.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.1.attn.qkv.weight", "model.3.model.layers.2.blocks.1.attn.qkv.bias", 
"model.3.model.layers.2.blocks.1.attn.proj.weight", "model.3.model.layers.2.blocks.1.attn.proj.bias", 
"model.3.model.layers.2.blocks.1.norm2.weight", "model.3.model.layers.2.blocks.1.norm2.bias", 
"model.3.model.layers.2.blocks.1.mlp.fc1.weight", "model.3.model.layers.2.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.1.mlp.fc2.weight", "model.3.model.layers.2.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.2.norm1.weight", "model.3.model.layers.2.blocks.2.norm1.bias", 
"model.3.model.layers.2.blocks.2.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.2.attn.qkv.weight", "model.3.model.layers.2.blocks.2.attn.qkv.bias", 
"model.3.model.layers.2.blocks.2.attn.proj.weight", "model.3.model.layers.2.blocks.2.attn.proj.bias", 
"model.3.model.layers.2.blocks.2.norm2.weight", "model.3.model.layers.2.blocks.2.norm2.bias", 
"model.3.model.layers.2.blocks.2.mlp.fc1.weight", "model.3.model.layers.2.blocks.2.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.2.mlp.fc2.weight", "model.3.model.layers.2.blocks.2.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.3.norm1.weight", "model.3.model.layers.2.blocks.3.norm1.bias", 
"model.3.model.layers.2.blocks.3.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.3.attn.qkv.weight", "model.3.model.layers.2.blocks.3.attn.qkv.bias", 
"model.3.model.layers.2.blocks.3.attn.proj.weight", "model.3.model.layers.2.blocks.3.attn.proj.bias", 
"model.3.model.layers.2.blocks.3.norm2.weight", "model.3.model.layers.2.blocks.3.norm2.bias", 
"model.3.model.layers.2.blocks.3.mlp.fc1.weight", "model.3.model.layers.2.blocks.3.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.3.mlp.fc2.weight", "model.3.model.layers.2.blocks.3.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.4.norm1.weight", "model.3.model.layers.2.blocks.4.norm1.bias", 
"model.3.model.layers.2.blocks.4.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.4.attn.qkv.weight", "model.3.model.layers.2.blocks.4.attn.qkv.bias", 
"model.3.model.layers.2.blocks.4.attn.proj.weight", "model.3.model.layers.2.blocks.4.attn.proj.bias", 
"model.3.model.layers.2.blocks.4.norm2.weight", "model.3.model.layers.2.blocks.4.norm2.bias", 
"model.3.model.layers.2.blocks.4.mlp.fc1.weight", "model.3.model.layers.2.blocks.4.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.4.mlp.fc2.weight", "model.3.model.layers.2.blocks.4.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.5.norm1.weight", "model.3.model.layers.2.blocks.5.norm1.bias", 
"model.3.model.layers.2.blocks.5.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.5.attn.qkv.weight", "model.3.model.layers.2.blocks.5.attn.qkv.bias", 
"model.3.model.layers.2.blocks.5.attn.proj.weight", "model.3.model.layers.2.blocks.5.attn.proj.bias", 
"model.3.model.layers.2.blocks.5.norm2.weight", "model.3.model.layers.2.blocks.5.norm2.bias", 
"model.3.model.layers.2.blocks.5.mlp.fc1.weight", "model.3.model.layers.2.blocks.5.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.5.mlp.fc2.weight", "model.3.model.layers.2.blocks.5.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.6.norm1.weight", "model.3.model.layers.2.blocks.6.norm1.bias", 
"model.3.model.layers.2.blocks.6.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.6.attn.qkv.weight", "model.3.model.layers.2.blocks.6.attn.qkv.bias", 
"model.3.model.layers.2.blocks.6.attn.proj.weight", "model.3.model.layers.2.blocks.6.attn.proj.bias", 
"model.3.model.layers.2.blocks.6.norm2.weight", "model.3.model.layers.2.blocks.6.norm2.bias", 
"model.3.model.layers.2.blocks.6.mlp.fc1.weight", "model.3.model.layers.2.blocks.6.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.6.mlp.fc2.weight", "model.3.model.layers.2.blocks.6.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.7.norm1.weight", "model.3.model.layers.2.blocks.7.norm1.bias", 
"model.3.model.layers.2.blocks.7.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.7.attn.qkv.weight", "model.3.model.layers.2.blocks.7.attn.qkv.bias", 
"model.3.model.layers.2.blocks.7.attn.proj.weight", "model.3.model.layers.2.blocks.7.attn.proj.bias", 
"model.3.model.layers.2.blocks.7.norm2.weight", "model.3.model.layers.2.blocks.7.norm2.bias", 
"model.3.model.layers.2.blocks.7.mlp.fc1.weight", "model.3.model.layers.2.blocks.7.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.7.mlp.fc2.weight", "model.3.model.layers.2.blocks.7.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.8.norm1.weight", "model.3.model.layers.2.blocks.8.norm1.bias", 
"model.3.model.layers.2.blocks.8.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.8.attn.qkv.weight", "model.3.model.layers.2.blocks.8.attn.qkv.bias", 
"model.3.model.layers.2.blocks.8.attn.proj.weight", "model.3.model.layers.2.blocks.8.attn.proj.bias", 
"model.3.model.layers.2.blocks.8.norm2.weight", "model.3.model.layers.2.blocks.8.norm2.bias", 
"model.3.model.layers.2.blocks.8.mlp.fc1.weight", "model.3.model.layers.2.blocks.8.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.8.mlp.fc2.weight", "model.3.model.layers.2.blocks.8.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.9.norm1.weight", "model.3.model.layers.2.blocks.9.norm1.bias", 
"model.3.model.layers.2.blocks.9.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.9.attn.qkv.weight", "model.3.model.layers.2.blocks.9.attn.qkv.bias", 
"model.3.model.layers.2.blocks.9.attn.proj.weight", "model.3.model.layers.2.blocks.9.attn.proj.bias", 
"model.3.model.layers.2.blocks.9.norm2.weight", "model.3.model.layers.2.blocks.9.norm2.bias", 
"model.3.model.layers.2.blocks.9.mlp.fc1.weight", "model.3.model.layers.2.blocks.9.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.9.mlp.fc2.weight", "model.3.model.layers.2.blocks.9.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.10.norm1.weight", "model.3.model.layers.2.blocks.10.norm1.bias", 
"model.3.model.layers.2.blocks.10.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.10.attn.qkv.weight", "model.3.model.layers.2.blocks.10.attn.qkv.bias", 
"model.3.model.layers.2.blocks.10.attn.proj.weight", "model.3.model.layers.2.blocks.10.attn.proj.bias", 
"model.3.model.layers.2.blocks.10.norm2.weight", "model.3.model.layers.2.blocks.10.norm2.bias", 
"model.3.model.layers.2.blocks.10.mlp.fc1.weight", "model.3.model.layers.2.blocks.10.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.10.mlp.fc2.weight", "model.3.model.layers.2.blocks.10.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.11.norm1.weight", "model.3.model.layers.2.blocks.11.norm1.bias", 
"model.3.model.layers.2.blocks.11.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.11.attn.qkv.weight", "model.3.model.layers.2.blocks.11.attn.qkv.bias", 
"model.3.model.layers.2.blocks.11.attn.proj.weight", "model.3.model.layers.2.blocks.11.attn.proj.bias", 
"model.3.model.layers.2.blocks.11.norm2.weight", "model.3.model.layers.2.blocks.11.norm2.bias", 
"model.3.model.layers.2.blocks.11.mlp.fc1.weight", "model.3.model.layers.2.blocks.11.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.11.mlp.fc2.weight", "model.3.model.layers.2.blocks.11.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.12.norm1.weight", "model.3.model.layers.2.blocks.12.norm1.bias", 
"model.3.model.layers.2.blocks.12.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.12.attn.qkv.weight", "model.3.model.layers.2.blocks.12.attn.qkv.bias", 
"model.3.model.layers.2.blocks.12.attn.proj.weight", "model.3.model.layers.2.blocks.12.attn.proj.bias", 
"model.3.model.layers.2.blocks.12.norm2.weight", "model.3.model.layers.2.blocks.12.norm2.bias", 
"model.3.model.layers.2.blocks.12.mlp.fc1.weight", "model.3.model.layers.2.blocks.12.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.12.mlp.fc2.weight", "model.3.model.layers.2.blocks.12.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.13.norm1.weight", "model.3.model.layers.2.blocks.13.norm1.bias", 
"model.3.model.layers.2.blocks.13.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.13.attn.qkv.weight", "model.3.model.layers.2.blocks.13.attn.qkv.bias", 
"model.3.model.layers.2.blocks.13.attn.proj.weight", "model.3.model.layers.2.blocks.13.attn.proj.bias", 
"model.3.model.layers.2.blocks.13.norm2.weight", "model.3.model.layers.2.blocks.13.norm2.bias", 
"model.3.model.layers.2.blocks.13.mlp.fc1.weight", "model.3.model.layers.2.blocks.13.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.13.mlp.fc2.weight", "model.3.model.layers.2.blocks.13.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.14.norm1.weight", "model.3.model.layers.2.blocks.14.norm1.bias", 
"model.3.model.layers.2.blocks.14.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.14.attn.qkv.weight", "model.3.model.layers.2.blocks.14.attn.qkv.bias", 
"model.3.model.layers.2.blocks.14.attn.proj.weight", "model.3.model.layers.2.blocks.14.attn.proj.bias", 
"model.3.model.layers.2.blocks.14.norm2.weight", "model.3.model.layers.2.blocks.14.norm2.bias", 
"model.3.model.layers.2.blocks.14.mlp.fc1.weight", "model.3.model.layers.2.blocks.14.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.14.mlp.fc2.weight", "model.3.model.layers.2.blocks.14.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.15.norm1.weight", "model.3.model.layers.2.blocks.15.norm1.bias", 
"model.3.model.layers.2.blocks.15.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.15.attn.qkv.weight", "model.3.model.layers.2.blocks.15.attn.qkv.bias", 
"model.3.model.layers.2.blocks.15.attn.proj.weight", "model.3.model.layers.2.blocks.15.attn.proj.bias", 
"model.3.model.layers.2.blocks.15.norm2.weight", "model.3.model.layers.2.blocks.15.norm2.bias", 
"model.3.model.layers.2.blocks.15.mlp.fc1.weight", "model.3.model.layers.2.blocks.15.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.15.mlp.fc2.weight", "model.3.model.layers.2.blocks.15.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.16.norm1.weight", "model.3.model.layers.2.blocks.16.norm1.bias", 
"model.3.model.layers.2.blocks.16.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.16.attn.qkv.weight", "model.3.model.layers.2.blocks.16.attn.qkv.bias", 
"model.3.model.layers.2.blocks.16.attn.proj.weight", "model.3.model.layers.2.blocks.16.attn.proj.bias", 
"model.3.model.layers.2.blocks.16.norm2.weight", "model.3.model.layers.2.blocks.16.norm2.bias", 
"model.3.model.layers.2.blocks.16.mlp.fc1.weight", "model.3.model.layers.2.blocks.16.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.16.mlp.fc2.weight", "model.3.model.layers.2.blocks.16.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.17.norm1.weight", "model.3.model.layers.2.blocks.17.norm1.bias", 
"model.3.model.layers.2.blocks.17.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.17.attn.qkv.weight", "model.3.model.layers.2.blocks.17.attn.qkv.bias", 
"model.3.model.layers.2.blocks.17.attn.proj.weight", "model.3.model.layers.2.blocks.17.attn.proj.bias", 
"model.3.model.layers.2.blocks.17.norm2.weight", "model.3.model.layers.2.blocks.17.norm2.bias", 
"model.3.model.layers.2.blocks.17.mlp.fc1.weight", "model.3.model.layers.2.blocks.17.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.17.mlp.fc2.weight", "model.3.model.layers.2.blocks.17.mlp.fc2.bias", 
"model.3.model.layers.3.downsample.norm.weight", "model.3.model.layers.3.downsample.norm.bias", 
"model.3.model.layers.3.downsample.reduction.weight", "model.3.model.layers.3.blocks.0.norm1.weight", 
"model.3.model.layers.3.blocks.0.norm1.bias", "model.3.model.layers.3.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.3.blocks.0.attn.qkv.weight", "model.3.model.layers.3.blocks.0.attn.qkv.bias", 
"model.3.model.layers.3.blocks.0.attn.proj.weight", "model.3.model.layers.3.blocks.0.attn.proj.bias", 
"model.3.model.layers.3.blocks.0.norm2.weight", "model.3.model.layers.3.blocks.0.norm2.bias", 
"model.3.model.layers.3.blocks.0.mlp.fc1.weight", "model.3.model.layers.3.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.3.blocks.0.mlp.fc2.weight", "model.3.model.layers.3.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.3.blocks.1.norm1.weight", "model.3.model.layers.3.blocks.1.norm1.bias", 
"model.3.model.layers.3.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.3.blocks.1.attn.qkv.weight", "model.3.model.layers.3.blocks.1.attn.qkv.bias", 
"model.3.model.layers.3.blocks.1.attn.proj.weight", "model.3.model.layers.3.blocks.1.attn.proj.bias", 
"model.3.model.layers.3.blocks.1.norm2.weight", "model.3.model.layers.3.blocks.1.norm2.bias", 
"model.3.model.layers.3.blocks.1.mlp.fc1.weight", "model.3.model.layers.3.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.3.blocks.1.mlp.fc2.weight", "model.3.model.layers.3.blocks.1.mlp.fc2.bias", 
"model.3.model.norm.weight", "model.3.model.norm.bias", "model.3.head.weight", "model.3.head.bias", 
"adapter.0.weight", "adapter.0.bias", "adapter.1.weight", "adapter.1.bias", "adapter.2.weight", "adapter.2.bias", 
"adapter.3.weight", "adapter.3.bias", "fusion_mlp.0.layers.0.norm.weight", "fusion_mlp.0.layers.0.norm.bias", 
"fusion_mlp.0.layers.0.fc.weight", "fusion_mlp.0.layers.0.fc.bias", "head.weight", "head.bias". 
        Unexpected key(s) in state_dict: "base_models.hf_text-electra.model.embeddings.position_ids", 
"base_models.hf_text-electra.model.embeddings.word_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.position_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.token_type_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.LayerNorm.weight", 
"base_models.hf_text-electra.model.embeddings.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.bias", 
"base_models.hf_text-electra.head.weight", "base_models.hf_text-electra.head.bias", 
"base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.weight", 
"base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.bias", 
"base_models.numerical_transformer.head.normalization.weight", 
"base_models.numerical_transformer.head.normalization.bias", 
"base_models.numerical_transformer.head.linear.weight", "base_models.numerical_transformer.head.linear.bias", 
"base_models.categorical_transformer.categorical_feature_tokenizer.bias", 
"base_models.categorical_transformer.categorical_feature_tokenizer.embeddings.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.bias", 
"base_models.categorical_transformer.head.normalization.weight", 
"base_models.categorical_transformer.head.normalization.bias", 
"base_models.categorical_transformer.head.linear.weight", "base_models.categorical_transformer.head.linear.bias", 
"base_models.timm_image-swin_transformer.model.patch_embed.proj.weight", 
"base_models.timm_image-swin_transformer.model.patch_embed.proj.bias", 
"base_models.timm_image-swin_transformer.model.patch_embed.norm.weight", 
"base_models.timm_image-swin_transformer.model.patch_embed.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.norm.weight", 
"base_models.timm_image-swin_transformer.model.norm.bias", "base_models.timm_image-swin_transformer.head.weight", 
"base_models.timm_image-swin_transformer.head.bias", "linear_layers.hf_text-electra.weight", 
"linear_layers.hf_text-electra.bias", "linear_layers.numerical_transformer.weight", 
"linear_layers.numerical_transformer.bias", "linear_layers.categorical_transformer.weight", 
"linear_layers.categorical_transformer.bias", "linear_layers.timm_image-swin_transformer.weight", 
"linear_layers.timm_image-swin_transformer.bias", "fusion_model.0.weight", "fusion_model.0.bias", 
"fusion_model.2.weight", "fusion_model.2.bias", "fusion_head.weight", "fusion_head.bias". 
