['model.base_models.hf_text-electra.model.embeddings.position_ids', 'model.base_models.hf_text-electra.model.embeddings.word_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.position_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.token_type_embeddings.weight', 'model.base_models.hf_text-electra.model.embeddings.LayerNorm.weight', 'model.base_models.hf_text-electra.model.embeddings.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.dense.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.dense.bias', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.weight', 'model.base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.bias', 'model.base_models.hf_text-electra.head.weight', 'model.base_models.hf_text-electra.head.bias', 'model.base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.weight', 'model.base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.attention_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.attention_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_q.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_q.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_k.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_k.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_v.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_v.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_out.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention.W_out.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.attention_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.attention_normalization.bias', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.weight', 'model.base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.bias', 'model.base_models.numerical_transformer.head.normalization.weight', 'model.base_models.numerical_transformer.head.normalization.bias', 'model.base_models.numerical_transformer.head.linear.weight', 'model.base_models.numerical_transformer.head.linear.bias', 'model.base_models.categorical_transformer.categorical_feature_tokenizer.bias', 'model.base_models.categorical_transformer.categorical_feature_tokenizer.embeddings.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.attention_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.attention_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_q.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_q.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_k.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_k.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_v.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_v.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_out.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention.W_out.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.attention_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.attention_normalization.bias', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.weight', 'model.base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.bias', 'model.base_models.categorical_transformer.head.normalization.weight', 'model.base_models.categorical_transformer.head.normalization.bias', 'model.base_models.categorical_transformer.head.linear.weight', 'model.base_models.categorical_transformer.head.linear.bias', 'model.base_models.timm_image-swin_transformer.model.patch_embed.proj.weight', 'model.base_models.timm_image-swin_transformer.model.patch_embed.proj.bias', 'model.base_models.timm_image-swin_transformer.model.patch_embed.norm.weight', 'model.base_models.timm_image-swin_transformer.model.patch_embed.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.downsample.reduction.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.relative_position_bias_table', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.bias', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.weight', 'model.base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.bias', 'model.base_models.timm_image-swin_transformer.model.norm.weight', 'model.base_models.timm_image-swin_transformer.model.norm.bias', 'model.base_models.timm_image-swin_transformer.head.weight', 'model.base_models.timm_image-swin_transformer.head.bias', 'model.linear_layers.hf_text-electra.weight', 'model.linear_layers.hf_text-electra.bias', 'model.linear_layers.numerical_transformer.weight', 'model.linear_layers.numerical_transformer.bias', 'model.linear_layers.categorical_transformer.weight', 'model.linear_layers.categorical_transformer.bias', 'model.linear_layers.timm_image-swin_transformer.weight', 'model.linear_layers.timm_image-swin_transformer.bias', 'model.fusion_model.0.weight', 'model.fusion_model.0.bias', 'model.fusion_model.2.weight', 'model.fusion_model.2.bias', 'model.fusion_head.weight', 'model.fusion_head.bias']
 Traceback (most recent call last) 
 in <module>:8                                                                                    
                                                                                                  
   5 os.environ["OPENAI_API_KEY"] = "sk-proj-a4DBFe76t6yhAmA6LzinROBjp5xTlYPChJo6uEYgfw5MHHHi     
   6 os.environ["OPENAI_API_BASE"] = "http://172.16.23.85:30592/chatgpt/api/ask"                  
   7                                                                                              
  8 predictor = AutoM3LPredictor.load("/home/ubuntu/autom3l/autom3l_code/output/petfinder_k1     
   9                                                                                              
                                                                                                  
 /home/ubuntu/autom3l/autom3l_code/multimodal/src/autom3l/multimodal/predictor_llm.py:3621 in     
 load                                                                                             
                                                                                                  
   3618          resume=resume,                                                                
   3619       )                                                                                 
   3620                                                                                         
  3621       model = cls._load_state_dict(                                                     
   3622          model=model,                                                                  
   3623          path=load_path,                                                               
   3624          strict=not efficient_finetune or efficient_finetune == "None",                
                                                                                                  
 /home/ubuntu/autom3l/autom3l_code/multimodal/src/autom3l/multimodal/predictor_llm.py:3341 in     
 _load_state_dict                                                                                 
                                                                                                  
   3338       state_dict = {k.partition(prefix)[2]: v for k, v in state_dict.items() if k.star  
   3339       #print("new_state_dict", state_dict)                                              
   3340       strict = True                                                                     
  3341       load_result = model.load_state_dict(state_dict, strict=strict)                    
   3342       '''                                                                               
   3343       assert (                                                                          
   3344          len(load_result.unexpected_keys) == 0                                         
                                                                                                  
 /home/ubuntu/.conda/envs/autom3l/lib/python3.9/site-packages/torch/nn/modules/module.py:1497 in  
 load_state_dict                                                                                  
                                                                                                  
   1494                   ', '.join('"{}"'.format(k) for k in missing_keys)))               
   1495                                                                                         
   1496       if len(error_msgs) > 0:                                                           
  1497          raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(     
   1498                         self.__class__.__name__, "\n\t".join(error_msgs)))         
   1499       return _IncompatibleKeys(missing_keys, unexpected_keys)                           
   1500                                                                                           

RuntimeError: Error(s) in loading state_dict for MultimodalFusionMLP:
        Missing key(s) in state_dict: "model.0.categorical_feature_tokenizer.bias", 
"model.0.categorical_feature_tokenizer.embeddings.weight", "model.0.transformer.blocks.0.attention.W_q.weight", 
"model.0.transformer.blocks.0.attention.W_q.bias", "model.0.transformer.blocks.0.attention.W_k.weight", 
"model.0.transformer.blocks.0.attention.W_k.bias", "model.0.transformer.blocks.0.attention.W_v.weight", 
"model.0.transformer.blocks.0.attention.W_v.bias", "model.0.transformer.blocks.0.attention.W_out.weight", 
"model.0.transformer.blocks.0.attention.W_out.bias", "model.0.transformer.blocks.0.ffn.linear_first.weight", 
"model.0.transformer.blocks.0.ffn.linear_first.bias", "model.0.transformer.blocks.0.ffn.linear_second.weight", 
"model.0.transformer.blocks.0.ffn.linear_second.bias", "model.0.transformer.blocks.0.ffn_normalization.weight", 
"model.0.transformer.blocks.0.ffn_normalization.bias", "model.0.transformer.blocks.1.attention.W_q.weight", 
"model.0.transformer.blocks.1.attention.W_q.bias", "model.0.transformer.blocks.1.attention.W_k.weight", 
"model.0.transformer.blocks.1.attention.W_k.bias", "model.0.transformer.blocks.1.attention.W_v.weight", 
"model.0.transformer.blocks.1.attention.W_v.bias", "model.0.transformer.blocks.1.attention.W_out.weight", 
"model.0.transformer.blocks.1.attention.W_out.bias", "model.0.transformer.blocks.1.ffn.linear_first.weight", 
"model.0.transformer.blocks.1.ffn.linear_first.bias", "model.0.transformer.blocks.1.ffn.linear_second.weight", 
"model.0.transformer.blocks.1.ffn.linear_second.bias", 
"model.0.transformer.blocks.1.attention_normalization.weight", 
"model.0.transformer.blocks.1.attention_normalization.bias", 
"model.0.transformer.blocks.1.ffn_normalization.weight", "model.0.transformer.blocks.1.ffn_normalization.bias", 
"model.0.transformer.blocks.2.attention.W_q.weight", "model.0.transformer.blocks.2.attention.W_q.bias", 
"model.0.transformer.blocks.2.attention.W_k.weight", "model.0.transformer.blocks.2.attention.W_k.bias", 
"model.0.transformer.blocks.2.attention.W_v.weight", "model.0.transformer.blocks.2.attention.W_v.bias", 
"model.0.transformer.blocks.2.attention.W_out.weight", "model.0.transformer.blocks.2.attention.W_out.bias", 
"model.0.transformer.blocks.2.ffn.linear_first.weight", "model.0.transformer.blocks.2.ffn.linear_first.bias", 
"model.0.transformer.blocks.2.ffn.linear_second.weight", "model.0.transformer.blocks.2.ffn.linear_second.bias", 
"model.0.transformer.blocks.2.attention_normalization.weight", 
"model.0.transformer.blocks.2.attention_normalization.bias", 
"model.0.transformer.blocks.2.ffn_normalization.weight", "model.0.transformer.blocks.2.ffn_normalization.bias", 
"model.0.head.normalization.weight", "model.0.head.normalization.bias", "model.0.head.linear.weight", 
"model.0.head.linear.bias", "model.1.model.embeddings.position_ids", 
"model.1.model.embeddings.word_embeddings.weight", "model.1.model.embeddings.position_embeddings.weight", 
"model.1.model.embeddings.token_type_embeddings.weight", "model.1.model.embeddings.LayerNorm.weight", 
"model.1.model.embeddings.LayerNorm.bias", "model.1.model.encoder.layer.0.attention.self.query.weight", 
"model.1.model.encoder.layer.0.attention.self.query.bias", 
"model.1.model.encoder.layer.0.attention.self.key.weight", "model.1.model.encoder.layer.0.attention.self.key.bias",
"model.1.model.encoder.layer.0.attention.self.value.weight", 
"model.1.model.encoder.layer.0.attention.self.value.bias", 
"model.1.model.encoder.layer.0.attention.output.dense.weight", 
"model.1.model.encoder.layer.0.attention.output.dense.bias", 
"model.1.model.encoder.layer.0.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.0.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.0.intermediate.dense.weight", "model.1.model.encoder.layer.0.intermediate.dense.bias",
"model.1.model.encoder.layer.0.output.dense.weight", "model.1.model.encoder.layer.0.output.dense.bias", 
"model.1.model.encoder.layer.0.output.LayerNorm.weight", "model.1.model.encoder.layer.0.output.LayerNorm.bias", 
"model.1.model.encoder.layer.1.attention.self.query.weight", 
"model.1.model.encoder.layer.1.attention.self.query.bias", 
"model.1.model.encoder.layer.1.attention.self.key.weight", "model.1.model.encoder.layer.1.attention.self.key.bias",
"model.1.model.encoder.layer.1.attention.self.value.weight", 
"model.1.model.encoder.layer.1.attention.self.value.bias", 
"model.1.model.encoder.layer.1.attention.output.dense.weight", 
"model.1.model.encoder.layer.1.attention.output.dense.bias", 
"model.1.model.encoder.layer.1.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.1.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.1.intermediate.dense.weight", "model.1.model.encoder.layer.1.intermediate.dense.bias",
"model.1.model.encoder.layer.1.output.dense.weight", "model.1.model.encoder.layer.1.output.dense.bias", 
"model.1.model.encoder.layer.1.output.LayerNorm.weight", "model.1.model.encoder.layer.1.output.LayerNorm.bias", 
"model.1.model.encoder.layer.2.attention.self.query.weight", 
"model.1.model.encoder.layer.2.attention.self.query.bias", 
"model.1.model.encoder.layer.2.attention.self.key.weight", "model.1.model.encoder.layer.2.attention.self.key.bias",
"model.1.model.encoder.layer.2.attention.self.value.weight", 
"model.1.model.encoder.layer.2.attention.self.value.bias", 
"model.1.model.encoder.layer.2.attention.output.dense.weight", 
"model.1.model.encoder.layer.2.attention.output.dense.bias", 
"model.1.model.encoder.layer.2.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.2.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.2.intermediate.dense.weight", "model.1.model.encoder.layer.2.intermediate.dense.bias",
"model.1.model.encoder.layer.2.output.dense.weight", "model.1.model.encoder.layer.2.output.dense.bias", 
"model.1.model.encoder.layer.2.output.LayerNorm.weight", "model.1.model.encoder.layer.2.output.LayerNorm.bias", 
"model.1.model.encoder.layer.3.attention.self.query.weight", 
"model.1.model.encoder.layer.3.attention.self.query.bias", 
"model.1.model.encoder.layer.3.attention.self.key.weight", "model.1.model.encoder.layer.3.attention.self.key.bias",
"model.1.model.encoder.layer.3.attention.self.value.weight", 
"model.1.model.encoder.layer.3.attention.self.value.bias", 
"model.1.model.encoder.layer.3.attention.output.dense.weight", 
"model.1.model.encoder.layer.3.attention.output.dense.bias", 
"model.1.model.encoder.layer.3.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.3.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.3.intermediate.dense.weight", "model.1.model.encoder.layer.3.intermediate.dense.bias",
"model.1.model.encoder.layer.3.output.dense.weight", "model.1.model.encoder.layer.3.output.dense.bias", 
"model.1.model.encoder.layer.3.output.LayerNorm.weight", "model.1.model.encoder.layer.3.output.LayerNorm.bias", 
"model.1.model.encoder.layer.4.attention.self.query.weight", 
"model.1.model.encoder.layer.4.attention.self.query.bias", 
"model.1.model.encoder.layer.4.attention.self.key.weight", "model.1.model.encoder.layer.4.attention.self.key.bias",
"model.1.model.encoder.layer.4.attention.self.value.weight", 
"model.1.model.encoder.layer.4.attention.self.value.bias", 
"model.1.model.encoder.layer.4.attention.output.dense.weight", 
"model.1.model.encoder.layer.4.attention.output.dense.bias", 
"model.1.model.encoder.layer.4.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.4.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.4.intermediate.dense.weight", "model.1.model.encoder.layer.4.intermediate.dense.bias",
"model.1.model.encoder.layer.4.output.dense.weight", "model.1.model.encoder.layer.4.output.dense.bias", 
"model.1.model.encoder.layer.4.output.LayerNorm.weight", "model.1.model.encoder.layer.4.output.LayerNorm.bias", 
"model.1.model.encoder.layer.5.attention.self.query.weight", 
"model.1.model.encoder.layer.5.attention.self.query.bias", 
"model.1.model.encoder.layer.5.attention.self.key.weight", "model.1.model.encoder.layer.5.attention.self.key.bias",
"model.1.model.encoder.layer.5.attention.self.value.weight", 
"model.1.model.encoder.layer.5.attention.self.value.bias", 
"model.1.model.encoder.layer.5.attention.output.dense.weight", 
"model.1.model.encoder.layer.5.attention.output.dense.bias", 
"model.1.model.encoder.layer.5.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.5.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.5.intermediate.dense.weight", "model.1.model.encoder.layer.5.intermediate.dense.bias",
"model.1.model.encoder.layer.5.output.dense.weight", "model.1.model.encoder.layer.5.output.dense.bias", 
"model.1.model.encoder.layer.5.output.LayerNorm.weight", "model.1.model.encoder.layer.5.output.LayerNorm.bias", 
"model.1.model.encoder.layer.6.attention.self.query.weight", 
"model.1.model.encoder.layer.6.attention.self.query.bias", 
"model.1.model.encoder.layer.6.attention.self.key.weight", "model.1.model.encoder.layer.6.attention.self.key.bias",
"model.1.model.encoder.layer.6.attention.self.value.weight", 
"model.1.model.encoder.layer.6.attention.self.value.bias", 
"model.1.model.encoder.layer.6.attention.output.dense.weight", 
"model.1.model.encoder.layer.6.attention.output.dense.bias", 
"model.1.model.encoder.layer.6.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.6.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.6.intermediate.dense.weight", "model.1.model.encoder.layer.6.intermediate.dense.bias",
"model.1.model.encoder.layer.6.output.dense.weight", "model.1.model.encoder.layer.6.output.dense.bias", 
"model.1.model.encoder.layer.6.output.LayerNorm.weight", "model.1.model.encoder.layer.6.output.LayerNorm.bias", 
"model.1.model.encoder.layer.7.attention.self.query.weight", 
"model.1.model.encoder.layer.7.attention.self.query.bias", 
"model.1.model.encoder.layer.7.attention.self.key.weight", "model.1.model.encoder.layer.7.attention.self.key.bias",
"model.1.model.encoder.layer.7.attention.self.value.weight", 
"model.1.model.encoder.layer.7.attention.self.value.bias", 
"model.1.model.encoder.layer.7.attention.output.dense.weight", 
"model.1.model.encoder.layer.7.attention.output.dense.bias", 
"model.1.model.encoder.layer.7.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.7.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.7.intermediate.dense.weight", "model.1.model.encoder.layer.7.intermediate.dense.bias",
"model.1.model.encoder.layer.7.output.dense.weight", "model.1.model.encoder.layer.7.output.dense.bias", 
"model.1.model.encoder.layer.7.output.LayerNorm.weight", "model.1.model.encoder.layer.7.output.LayerNorm.bias", 
"model.1.model.encoder.layer.8.attention.self.query.weight", 
"model.1.model.encoder.layer.8.attention.self.query.bias", 
"model.1.model.encoder.layer.8.attention.self.key.weight", "model.1.model.encoder.layer.8.attention.self.key.bias",
"model.1.model.encoder.layer.8.attention.self.value.weight", 
"model.1.model.encoder.layer.8.attention.self.value.bias", 
"model.1.model.encoder.layer.8.attention.output.dense.weight", 
"model.1.model.encoder.layer.8.attention.output.dense.bias", 
"model.1.model.encoder.layer.8.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.8.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.8.intermediate.dense.weight", "model.1.model.encoder.layer.8.intermediate.dense.bias",
"model.1.model.encoder.layer.8.output.dense.weight", "model.1.model.encoder.layer.8.output.dense.bias", 
"model.1.model.encoder.layer.8.output.LayerNorm.weight", "model.1.model.encoder.layer.8.output.LayerNorm.bias", 
"model.1.model.encoder.layer.9.attention.self.query.weight", 
"model.1.model.encoder.layer.9.attention.self.query.bias", 
"model.1.model.encoder.layer.9.attention.self.key.weight", "model.1.model.encoder.layer.9.attention.self.key.bias",
"model.1.model.encoder.layer.9.attention.self.value.weight", 
"model.1.model.encoder.layer.9.attention.self.value.bias", 
"model.1.model.encoder.layer.9.attention.output.dense.weight", 
"model.1.model.encoder.layer.9.attention.output.dense.bias", 
"model.1.model.encoder.layer.9.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.9.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.9.intermediate.dense.weight", "model.1.model.encoder.layer.9.intermediate.dense.bias",
"model.1.model.encoder.layer.9.output.dense.weight", "model.1.model.encoder.layer.9.output.dense.bias", 
"model.1.model.encoder.layer.9.output.LayerNorm.weight", "model.1.model.encoder.layer.9.output.LayerNorm.bias", 
"model.1.model.encoder.layer.10.attention.self.query.weight", 
"model.1.model.encoder.layer.10.attention.self.query.bias", 
"model.1.model.encoder.layer.10.attention.self.key.weight", 
"model.1.model.encoder.layer.10.attention.self.key.bias", 
"model.1.model.encoder.layer.10.attention.self.value.weight", 
"model.1.model.encoder.layer.10.attention.self.value.bias", 
"model.1.model.encoder.layer.10.attention.output.dense.weight", 
"model.1.model.encoder.layer.10.attention.output.dense.bias", 
"model.1.model.encoder.layer.10.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.10.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.10.intermediate.dense.weight", 
"model.1.model.encoder.layer.10.intermediate.dense.bias", "model.1.model.encoder.layer.10.output.dense.weight", 
"model.1.model.encoder.layer.10.output.dense.bias", "model.1.model.encoder.layer.10.output.LayerNorm.weight", 
"model.1.model.encoder.layer.10.output.LayerNorm.bias", 
"model.1.model.encoder.layer.11.attention.self.query.weight", 
"model.1.model.encoder.layer.11.attention.self.query.bias", 
"model.1.model.encoder.layer.11.attention.self.key.weight", 
"model.1.model.encoder.layer.11.attention.self.key.bias", 
"model.1.model.encoder.layer.11.attention.self.value.weight", 
"model.1.model.encoder.layer.11.attention.self.value.bias", 
"model.1.model.encoder.layer.11.attention.output.dense.weight", 
"model.1.model.encoder.layer.11.attention.output.dense.bias", 
"model.1.model.encoder.layer.11.attention.output.LayerNorm.weight", 
"model.1.model.encoder.layer.11.attention.output.LayerNorm.bias", 
"model.1.model.encoder.layer.11.intermediate.dense.weight", 
"model.1.model.encoder.layer.11.intermediate.dense.bias", "model.1.model.encoder.layer.11.output.dense.weight", 
"model.1.model.encoder.layer.11.output.dense.bias", "model.1.model.encoder.layer.11.output.LayerNorm.weight", 
"model.1.model.encoder.layer.11.output.LayerNorm.bias", "model.1.head.weight", "model.1.head.bias", 
"model.2.numerical_feature_tokenizer.layers.0.weight", "model.2.numerical_feature_tokenizer.layers.0.bias", 
"model.2.transformer.blocks.0.attention.W_q.weight", "model.2.transformer.blocks.0.attention.W_q.bias", 
"model.2.transformer.blocks.0.attention.W_k.weight", "model.2.transformer.blocks.0.attention.W_k.bias", 
"model.2.transformer.blocks.0.attention.W_v.weight", "model.2.transformer.blocks.0.attention.W_v.bias", 
"model.2.transformer.blocks.0.attention.W_out.weight", "model.2.transformer.blocks.0.attention.W_out.bias", 
"model.2.transformer.blocks.0.ffn.linear_first.weight", "model.2.transformer.blocks.0.ffn.linear_first.bias", 
"model.2.transformer.blocks.0.ffn.linear_second.weight", "model.2.transformer.blocks.0.ffn.linear_second.bias", 
"model.2.transformer.blocks.0.ffn_normalization.weight", "model.2.transformer.blocks.0.ffn_normalization.bias", 
"model.2.transformer.blocks.1.attention.W_q.weight", "model.2.transformer.blocks.1.attention.W_q.bias", 
"model.2.transformer.blocks.1.attention.W_k.weight", "model.2.transformer.blocks.1.attention.W_k.bias", 
"model.2.transformer.blocks.1.attention.W_v.weight", "model.2.transformer.blocks.1.attention.W_v.bias", 
"model.2.transformer.blocks.1.attention.W_out.weight", "model.2.transformer.blocks.1.attention.W_out.bias", 
"model.2.transformer.blocks.1.ffn.linear_first.weight", "model.2.transformer.blocks.1.ffn.linear_first.bias", 
"model.2.transformer.blocks.1.ffn.linear_second.weight", "model.2.transformer.blocks.1.ffn.linear_second.bias", 
"model.2.transformer.blocks.1.attention_normalization.weight", 
"model.2.transformer.blocks.1.attention_normalization.bias", 
"model.2.transformer.blocks.1.ffn_normalization.weight", "model.2.transformer.blocks.1.ffn_normalization.bias", 
"model.2.transformer.blocks.2.attention.W_q.weight", "model.2.transformer.blocks.2.attention.W_q.bias", 
"model.2.transformer.blocks.2.attention.W_k.weight", "model.2.transformer.blocks.2.attention.W_k.bias", 
"model.2.transformer.blocks.2.attention.W_v.weight", "model.2.transformer.blocks.2.attention.W_v.bias", 
"model.2.transformer.blocks.2.attention.W_out.weight", "model.2.transformer.blocks.2.attention.W_out.bias", 
"model.2.transformer.blocks.2.ffn.linear_first.weight", "model.2.transformer.blocks.2.ffn.linear_first.bias", 
"model.2.transformer.blocks.2.ffn.linear_second.weight", "model.2.transformer.blocks.2.ffn.linear_second.bias", 
"model.2.transformer.blocks.2.attention_normalization.weight", 
"model.2.transformer.blocks.2.attention_normalization.bias", 
"model.2.transformer.blocks.2.ffn_normalization.weight", "model.2.transformer.blocks.2.ffn_normalization.bias", 
"model.2.head.normalization.weight", "model.2.head.normalization.bias", "model.2.head.linear.weight", 
"model.2.head.linear.bias", "model.3.model.patch_embed.proj.weight", "model.3.model.patch_embed.proj.bias", 
"model.3.model.patch_embed.norm.weight", "model.3.model.patch_embed.norm.bias", 
"model.3.model.layers.0.blocks.0.norm1.weight", "model.3.model.layers.0.blocks.0.norm1.bias", 
"model.3.model.layers.0.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.0.blocks.0.attn.qkv.weight", "model.3.model.layers.0.blocks.0.attn.qkv.bias", 
"model.3.model.layers.0.blocks.0.attn.proj.weight", "model.3.model.layers.0.blocks.0.attn.proj.bias", 
"model.3.model.layers.0.blocks.0.norm2.weight", "model.3.model.layers.0.blocks.0.norm2.bias", 
"model.3.model.layers.0.blocks.0.mlp.fc1.weight", "model.3.model.layers.0.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.0.blocks.0.mlp.fc2.weight", "model.3.model.layers.0.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.0.blocks.1.norm1.weight", "model.3.model.layers.0.blocks.1.norm1.bias", 
"model.3.model.layers.0.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.0.blocks.1.attn.qkv.weight", "model.3.model.layers.0.blocks.1.attn.qkv.bias", 
"model.3.model.layers.0.blocks.1.attn.proj.weight", "model.3.model.layers.0.blocks.1.attn.proj.bias", 
"model.3.model.layers.0.blocks.1.norm2.weight", "model.3.model.layers.0.blocks.1.norm2.bias", 
"model.3.model.layers.0.blocks.1.mlp.fc1.weight", "model.3.model.layers.0.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.0.blocks.1.mlp.fc2.weight", "model.3.model.layers.0.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.1.downsample.norm.weight", "model.3.model.layers.1.downsample.norm.bias", 
"model.3.model.layers.1.downsample.reduction.weight", "model.3.model.layers.1.blocks.0.norm1.weight", 
"model.3.model.layers.1.blocks.0.norm1.bias", "model.3.model.layers.1.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.1.blocks.0.attn.qkv.weight", "model.3.model.layers.1.blocks.0.attn.qkv.bias", 
"model.3.model.layers.1.blocks.0.attn.proj.weight", "model.3.model.layers.1.blocks.0.attn.proj.bias", 
"model.3.model.layers.1.blocks.0.norm2.weight", "model.3.model.layers.1.blocks.0.norm2.bias", 
"model.3.model.layers.1.blocks.0.mlp.fc1.weight", "model.3.model.layers.1.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.1.blocks.0.mlp.fc2.weight", "model.3.model.layers.1.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.1.blocks.1.norm1.weight", "model.3.model.layers.1.blocks.1.norm1.bias", 
"model.3.model.layers.1.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.1.blocks.1.attn.qkv.weight", "model.3.model.layers.1.blocks.1.attn.qkv.bias", 
"model.3.model.layers.1.blocks.1.attn.proj.weight", "model.3.model.layers.1.blocks.1.attn.proj.bias", 
"model.3.model.layers.1.blocks.1.norm2.weight", "model.3.model.layers.1.blocks.1.norm2.bias", 
"model.3.model.layers.1.blocks.1.mlp.fc1.weight", "model.3.model.layers.1.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.1.blocks.1.mlp.fc2.weight", "model.3.model.layers.1.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.2.downsample.norm.weight", "model.3.model.layers.2.downsample.norm.bias", 
"model.3.model.layers.2.downsample.reduction.weight", "model.3.model.layers.2.blocks.0.norm1.weight", 
"model.3.model.layers.2.blocks.0.norm1.bias", "model.3.model.layers.2.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.0.attn.qkv.weight", "model.3.model.layers.2.blocks.0.attn.qkv.bias", 
"model.3.model.layers.2.blocks.0.attn.proj.weight", "model.3.model.layers.2.blocks.0.attn.proj.bias", 
"model.3.model.layers.2.blocks.0.norm2.weight", "model.3.model.layers.2.blocks.0.norm2.bias", 
"model.3.model.layers.2.blocks.0.mlp.fc1.weight", "model.3.model.layers.2.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.0.mlp.fc2.weight", "model.3.model.layers.2.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.1.norm1.weight", "model.3.model.layers.2.blocks.1.norm1.bias", 
"model.3.model.layers.2.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.1.attn.qkv.weight", "model.3.model.layers.2.blocks.1.attn.qkv.bias", 
"model.3.model.layers.2.blocks.1.attn.proj.weight", "model.3.model.layers.2.blocks.1.attn.proj.bias", 
"model.3.model.layers.2.blocks.1.norm2.weight", "model.3.model.layers.2.blocks.1.norm2.bias", 
"model.3.model.layers.2.blocks.1.mlp.fc1.weight", "model.3.model.layers.2.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.1.mlp.fc2.weight", "model.3.model.layers.2.blocks.1.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.2.norm1.weight", "model.3.model.layers.2.blocks.2.norm1.bias", 
"model.3.model.layers.2.blocks.2.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.2.attn.qkv.weight", "model.3.model.layers.2.blocks.2.attn.qkv.bias", 
"model.3.model.layers.2.blocks.2.attn.proj.weight", "model.3.model.layers.2.blocks.2.attn.proj.bias", 
"model.3.model.layers.2.blocks.2.norm2.weight", "model.3.model.layers.2.blocks.2.norm2.bias", 
"model.3.model.layers.2.blocks.2.mlp.fc1.weight", "model.3.model.layers.2.blocks.2.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.2.mlp.fc2.weight", "model.3.model.layers.2.blocks.2.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.3.norm1.weight", "model.3.model.layers.2.blocks.3.norm1.bias", 
"model.3.model.layers.2.blocks.3.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.3.attn.qkv.weight", "model.3.model.layers.2.blocks.3.attn.qkv.bias", 
"model.3.model.layers.2.blocks.3.attn.proj.weight", "model.3.model.layers.2.blocks.3.attn.proj.bias", 
"model.3.model.layers.2.blocks.3.norm2.weight", "model.3.model.layers.2.blocks.3.norm2.bias", 
"model.3.model.layers.2.blocks.3.mlp.fc1.weight", "model.3.model.layers.2.blocks.3.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.3.mlp.fc2.weight", "model.3.model.layers.2.blocks.3.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.4.norm1.weight", "model.3.model.layers.2.blocks.4.norm1.bias", 
"model.3.model.layers.2.blocks.4.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.4.attn.qkv.weight", "model.3.model.layers.2.blocks.4.attn.qkv.bias", 
"model.3.model.layers.2.blocks.4.attn.proj.weight", "model.3.model.layers.2.blocks.4.attn.proj.bias", 
"model.3.model.layers.2.blocks.4.norm2.weight", "model.3.model.layers.2.blocks.4.norm2.bias", 
"model.3.model.layers.2.blocks.4.mlp.fc1.weight", "model.3.model.layers.2.blocks.4.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.4.mlp.fc2.weight", "model.3.model.layers.2.blocks.4.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.5.norm1.weight", "model.3.model.layers.2.blocks.5.norm1.bias", 
"model.3.model.layers.2.blocks.5.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.5.attn.qkv.weight", "model.3.model.layers.2.blocks.5.attn.qkv.bias", 
"model.3.model.layers.2.blocks.5.attn.proj.weight", "model.3.model.layers.2.blocks.5.attn.proj.bias", 
"model.3.model.layers.2.blocks.5.norm2.weight", "model.3.model.layers.2.blocks.5.norm2.bias", 
"model.3.model.layers.2.blocks.5.mlp.fc1.weight", "model.3.model.layers.2.blocks.5.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.5.mlp.fc2.weight", "model.3.model.layers.2.blocks.5.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.6.norm1.weight", "model.3.model.layers.2.blocks.6.norm1.bias", 
"model.3.model.layers.2.blocks.6.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.6.attn.qkv.weight", "model.3.model.layers.2.blocks.6.attn.qkv.bias", 
"model.3.model.layers.2.blocks.6.attn.proj.weight", "model.3.model.layers.2.blocks.6.attn.proj.bias", 
"model.3.model.layers.2.blocks.6.norm2.weight", "model.3.model.layers.2.blocks.6.norm2.bias", 
"model.3.model.layers.2.blocks.6.mlp.fc1.weight", "model.3.model.layers.2.blocks.6.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.6.mlp.fc2.weight", "model.3.model.layers.2.blocks.6.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.7.norm1.weight", "model.3.model.layers.2.blocks.7.norm1.bias", 
"model.3.model.layers.2.blocks.7.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.7.attn.qkv.weight", "model.3.model.layers.2.blocks.7.attn.qkv.bias", 
"model.3.model.layers.2.blocks.7.attn.proj.weight", "model.3.model.layers.2.blocks.7.attn.proj.bias", 
"model.3.model.layers.2.blocks.7.norm2.weight", "model.3.model.layers.2.blocks.7.norm2.bias", 
"model.3.model.layers.2.blocks.7.mlp.fc1.weight", "model.3.model.layers.2.blocks.7.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.7.mlp.fc2.weight", "model.3.model.layers.2.blocks.7.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.8.norm1.weight", "model.3.model.layers.2.blocks.8.norm1.bias", 
"model.3.model.layers.2.blocks.8.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.8.attn.qkv.weight", "model.3.model.layers.2.blocks.8.attn.qkv.bias", 
"model.3.model.layers.2.blocks.8.attn.proj.weight", "model.3.model.layers.2.blocks.8.attn.proj.bias", 
"model.3.model.layers.2.blocks.8.norm2.weight", "model.3.model.layers.2.blocks.8.norm2.bias", 
"model.3.model.layers.2.blocks.8.mlp.fc1.weight", "model.3.model.layers.2.blocks.8.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.8.mlp.fc2.weight", "model.3.model.layers.2.blocks.8.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.9.norm1.weight", "model.3.model.layers.2.blocks.9.norm1.bias", 
"model.3.model.layers.2.blocks.9.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.9.attn.qkv.weight", "model.3.model.layers.2.blocks.9.attn.qkv.bias", 
"model.3.model.layers.2.blocks.9.attn.proj.weight", "model.3.model.layers.2.blocks.9.attn.proj.bias", 
"model.3.model.layers.2.blocks.9.norm2.weight", "model.3.model.layers.2.blocks.9.norm2.bias", 
"model.3.model.layers.2.blocks.9.mlp.fc1.weight", "model.3.model.layers.2.blocks.9.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.9.mlp.fc2.weight", "model.3.model.layers.2.blocks.9.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.10.norm1.weight", "model.3.model.layers.2.blocks.10.norm1.bias", 
"model.3.model.layers.2.blocks.10.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.10.attn.qkv.weight", "model.3.model.layers.2.blocks.10.attn.qkv.bias", 
"model.3.model.layers.2.blocks.10.attn.proj.weight", "model.3.model.layers.2.blocks.10.attn.proj.bias", 
"model.3.model.layers.2.blocks.10.norm2.weight", "model.3.model.layers.2.blocks.10.norm2.bias", 
"model.3.model.layers.2.blocks.10.mlp.fc1.weight", "model.3.model.layers.2.blocks.10.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.10.mlp.fc2.weight", "model.3.model.layers.2.blocks.10.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.11.norm1.weight", "model.3.model.layers.2.blocks.11.norm1.bias", 
"model.3.model.layers.2.blocks.11.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.11.attn.qkv.weight", "model.3.model.layers.2.blocks.11.attn.qkv.bias", 
"model.3.model.layers.2.blocks.11.attn.proj.weight", "model.3.model.layers.2.blocks.11.attn.proj.bias", 
"model.3.model.layers.2.blocks.11.norm2.weight", "model.3.model.layers.2.blocks.11.norm2.bias", 
"model.3.model.layers.2.blocks.11.mlp.fc1.weight", "model.3.model.layers.2.blocks.11.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.11.mlp.fc2.weight", "model.3.model.layers.2.blocks.11.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.12.norm1.weight", "model.3.model.layers.2.blocks.12.norm1.bias", 
"model.3.model.layers.2.blocks.12.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.12.attn.qkv.weight", "model.3.model.layers.2.blocks.12.attn.qkv.bias", 
"model.3.model.layers.2.blocks.12.attn.proj.weight", "model.3.model.layers.2.blocks.12.attn.proj.bias", 
"model.3.model.layers.2.blocks.12.norm2.weight", "model.3.model.layers.2.blocks.12.norm2.bias", 
"model.3.model.layers.2.blocks.12.mlp.fc1.weight", "model.3.model.layers.2.blocks.12.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.12.mlp.fc2.weight", "model.3.model.layers.2.blocks.12.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.13.norm1.weight", "model.3.model.layers.2.blocks.13.norm1.bias", 
"model.3.model.layers.2.blocks.13.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.13.attn.qkv.weight", "model.3.model.layers.2.blocks.13.attn.qkv.bias", 
"model.3.model.layers.2.blocks.13.attn.proj.weight", "model.3.model.layers.2.blocks.13.attn.proj.bias", 
"model.3.model.layers.2.blocks.13.norm2.weight", "model.3.model.layers.2.blocks.13.norm2.bias", 
"model.3.model.layers.2.blocks.13.mlp.fc1.weight", "model.3.model.layers.2.blocks.13.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.13.mlp.fc2.weight", "model.3.model.layers.2.blocks.13.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.14.norm1.weight", "model.3.model.layers.2.blocks.14.norm1.bias", 
"model.3.model.layers.2.blocks.14.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.14.attn.qkv.weight", "model.3.model.layers.2.blocks.14.attn.qkv.bias", 
"model.3.model.layers.2.blocks.14.attn.proj.weight", "model.3.model.layers.2.blocks.14.attn.proj.bias", 
"model.3.model.layers.2.blocks.14.norm2.weight", "model.3.model.layers.2.blocks.14.norm2.bias", 
"model.3.model.layers.2.blocks.14.mlp.fc1.weight", "model.3.model.layers.2.blocks.14.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.14.mlp.fc2.weight", "model.3.model.layers.2.blocks.14.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.15.norm1.weight", "model.3.model.layers.2.blocks.15.norm1.bias", 
"model.3.model.layers.2.blocks.15.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.15.attn.qkv.weight", "model.3.model.layers.2.blocks.15.attn.qkv.bias", 
"model.3.model.layers.2.blocks.15.attn.proj.weight", "model.3.model.layers.2.blocks.15.attn.proj.bias", 
"model.3.model.layers.2.blocks.15.norm2.weight", "model.3.model.layers.2.blocks.15.norm2.bias", 
"model.3.model.layers.2.blocks.15.mlp.fc1.weight", "model.3.model.layers.2.blocks.15.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.15.mlp.fc2.weight", "model.3.model.layers.2.blocks.15.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.16.norm1.weight", "model.3.model.layers.2.blocks.16.norm1.bias", 
"model.3.model.layers.2.blocks.16.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.16.attn.qkv.weight", "model.3.model.layers.2.blocks.16.attn.qkv.bias", 
"model.3.model.layers.2.blocks.16.attn.proj.weight", "model.3.model.layers.2.blocks.16.attn.proj.bias", 
"model.3.model.layers.2.blocks.16.norm2.weight", "model.3.model.layers.2.blocks.16.norm2.bias", 
"model.3.model.layers.2.blocks.16.mlp.fc1.weight", "model.3.model.layers.2.blocks.16.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.16.mlp.fc2.weight", "model.3.model.layers.2.blocks.16.mlp.fc2.bias", 
"model.3.model.layers.2.blocks.17.norm1.weight", "model.3.model.layers.2.blocks.17.norm1.bias", 
"model.3.model.layers.2.blocks.17.attn.relative_position_bias_table", 
"model.3.model.layers.2.blocks.17.attn.qkv.weight", "model.3.model.layers.2.blocks.17.attn.qkv.bias", 
"model.3.model.layers.2.blocks.17.attn.proj.weight", "model.3.model.layers.2.blocks.17.attn.proj.bias", 
"model.3.model.layers.2.blocks.17.norm2.weight", "model.3.model.layers.2.blocks.17.norm2.bias", 
"model.3.model.layers.2.blocks.17.mlp.fc1.weight", "model.3.model.layers.2.blocks.17.mlp.fc1.bias", 
"model.3.model.layers.2.blocks.17.mlp.fc2.weight", "model.3.model.layers.2.blocks.17.mlp.fc2.bias", 
"model.3.model.layers.3.downsample.norm.weight", "model.3.model.layers.3.downsample.norm.bias", 
"model.3.model.layers.3.downsample.reduction.weight", "model.3.model.layers.3.blocks.0.norm1.weight", 
"model.3.model.layers.3.blocks.0.norm1.bias", "model.3.model.layers.3.blocks.0.attn.relative_position_bias_table", 
"model.3.model.layers.3.blocks.0.attn.qkv.weight", "model.3.model.layers.3.blocks.0.attn.qkv.bias", 
"model.3.model.layers.3.blocks.0.attn.proj.weight", "model.3.model.layers.3.blocks.0.attn.proj.bias", 
"model.3.model.layers.3.blocks.0.norm2.weight", "model.3.model.layers.3.blocks.0.norm2.bias", 
"model.3.model.layers.3.blocks.0.mlp.fc1.weight", "model.3.model.layers.3.blocks.0.mlp.fc1.bias", 
"model.3.model.layers.3.blocks.0.mlp.fc2.weight", "model.3.model.layers.3.blocks.0.mlp.fc2.bias", 
"model.3.model.layers.3.blocks.1.norm1.weight", "model.3.model.layers.3.blocks.1.norm1.bias", 
"model.3.model.layers.3.blocks.1.attn.relative_position_bias_table", 
"model.3.model.layers.3.blocks.1.attn.qkv.weight", "model.3.model.layers.3.blocks.1.attn.qkv.bias", 
"model.3.model.layers.3.blocks.1.attn.proj.weight", "model.3.model.layers.3.blocks.1.attn.proj.bias", 
"model.3.model.layers.3.blocks.1.norm2.weight", "model.3.model.layers.3.blocks.1.norm2.bias", 
"model.3.model.layers.3.blocks.1.mlp.fc1.weight", "model.3.model.layers.3.blocks.1.mlp.fc1.bias", 
"model.3.model.layers.3.blocks.1.mlp.fc2.weight", "model.3.model.layers.3.blocks.1.mlp.fc2.bias", 
"model.3.model.norm.weight", "model.3.model.norm.bias", "model.3.head.weight", "model.3.head.bias", 
"adapter.0.weight", "adapter.0.bias", "adapter.1.weight", "adapter.1.bias", "adapter.2.weight", "adapter.2.bias", 
"adapter.3.weight", "adapter.3.bias", "fusion_mlp.0.layers.0.norm.weight", "fusion_mlp.0.layers.0.norm.bias", 
"fusion_mlp.0.layers.0.fc.weight", "fusion_mlp.0.layers.0.fc.bias", "head.weight", "head.bias". 
        Unexpected key(s) in state_dict: "base_models.hf_text-electra.model.embeddings.position_ids", 
"base_models.hf_text-electra.model.embeddings.word_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.position_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.token_type_embeddings.weight", 
"base_models.hf_text-electra.model.embeddings.LayerNorm.weight", 
"base_models.hf_text-electra.model.embeddings.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.0.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.1.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.2.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.3.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.4.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.5.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.6.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.7.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.8.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.9.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.10.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.query.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.key.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.self.value.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.attention.output.LayerNorm.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.intermediate.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.output.dense.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.output.dense.bias", 
"base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.weight", 
"base_models.hf_text-electra.model.encoder.layer.11.output.LayerNorm.bias", 
"base_models.hf_text-electra.head.weight", "base_models.hf_text-electra.head.bias", 
"base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.weight", 
"base_models.numerical_transformer.numerical_feature_tokenizer.layers.0.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.0.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.0.ffn_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.1.attention_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.1.attention_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.1.ffn_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_q.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_q.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_k.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_k.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_v.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_v.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_out.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention.W_out.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_first.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn.linear_second.bias", 
"base_models.numerical_transformer.transformer.blocks.2.attention_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.2.attention_normalization.bias", 
"base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.weight", 
"base_models.numerical_transformer.transformer.blocks.2.ffn_normalization.bias", 
"base_models.numerical_transformer.head.normalization.weight", 
"base_models.numerical_transformer.head.normalization.bias", 
"base_models.numerical_transformer.head.linear.weight", "base_models.numerical_transformer.head.linear.bias", 
"base_models.categorical_transformer.categorical_feature_tokenizer.bias", 
"base_models.categorical_transformer.categorical_feature_tokenizer.embeddings.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.0.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.0.ffn_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.1.attention_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.1.attention_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.1.ffn_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_q.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_q.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_k.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_k.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_v.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_v.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_out.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention.W_out.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_first.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn.linear_second.bias", 
"base_models.categorical_transformer.transformer.blocks.2.attention_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.2.attention_normalization.bias", 
"base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.weight", 
"base_models.categorical_transformer.transformer.blocks.2.ffn_normalization.bias", 
"base_models.categorical_transformer.head.normalization.weight", 
"base_models.categorical_transformer.head.normalization.bias", 
"base_models.categorical_transformer.head.linear.weight", "base_models.categorical_transformer.head.linear.bias", 
"base_models.timm_image-swin_transformer.model.patch_embed.proj.weight", 
"base_models.timm_image-swin_transformer.model.patch_embed.proj.bias", 
"base_models.timm_image-swin_transformer.model.patch_embed.norm.weight", 
"base_models.timm_image-swin_transformer.model.patch_embed.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.0.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.1.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.2.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.3.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.4.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.5.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.6.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.7.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.8.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.9.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.10.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.11.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.12.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.13.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.14.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.15.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.16.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.2.blocks.17.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.norm.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.downsample.reduction.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.0.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.relative_position_bias_table", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.qkv.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.attn.proj.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.norm2.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc1.bias", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.weight", 
"base_models.timm_image-swin_transformer.model.layers.3.blocks.1.mlp.fc2.bias", 
"base_models.timm_image-swin_transformer.model.norm.weight", 
"base_models.timm_image-swin_transformer.model.norm.bias", "base_models.timm_image-swin_transformer.head.weight", 
"base_models.timm_image-swin_transformer.head.bias", "linear_layers.hf_text-electra.weight", 
"linear_layers.hf_text-electra.bias", "linear_layers.numerical_transformer.weight", 
"linear_layers.numerical_transformer.bias", "linear_layers.categorical_transformer.weight", 
"linear_layers.categorical_transformer.bias", "linear_layers.timm_image-swin_transformer.weight", 
"linear_layers.timm_image-swin_transformer.bias", "fusion_model.0.weight", "fusion_model.0.bias", 
"fusion_model.2.weight", "fusion_model.2.bias", "fusion_head.weight", "fusion_head.bias". 
